{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54a819d-e8f7-4be7-b7f4-9b3f35143c29",
   "metadata": {},
   "source": [
    "# MLP for CIFAR10\n",
    "\n",
    "This is very similar to the MNIST MLP. Notable changes will be highlighted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b53d9a-c7e1-45d6-9fa6-41d1c7a90aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e9824-d75d-4ed3-ab13-59058a953240",
   "metadata": {},
   "source": [
    "`torchvision` comes with the CIFAR datasets, so we just download it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829922e-0a81-4dc0-a969-3aca9df8bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56744fd-68e7-41b2-8f6b-b01287d584c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                              num_workers=8)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size,\n",
    "                             num_workers=8)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88facf7-8080-4b83-b5c9-92ebf2ff2b6f",
   "metadata": {},
   "source": [
    "## Plotting training data\n",
    "\n",
    "It is generally a good idea to have a look at our data. This is especially true if you include data augmentation -- you can make sure that your augmentations aren't too extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b2d71-2cb6-4a96-b853-3a3055c670e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, _ in train_dataloader:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for ind, img in enumerate(X):\n",
    "        plt.subplot(8, 16, ind+1)\n",
    "        plt.imshow(img.permute((1, 2, 0)))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d2c571-aaa6-4f1a-aed5-7f1484d64452",
   "metadata": {},
   "source": [
    "We could also look a some dataset statistics again! We can see that the pixel vaule distribution is very different from MNIST; while there are still peaks near 0 and 1, we have plenty of values inbetween, with a sort-of Gaussian distribution. Also, the labels are actually balanced; there are 5000 images for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948f691-f38a-4863-aab8-f916941f73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we gotta extract the data from the dataloader\n",
    "images_np = []\n",
    "labels_np = []\n",
    "\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    images_np.append(image_batch.numpy())\n",
    "    labels_np.append(label_batch.numpy())\n",
    "\n",
    "images_np = np.concatenate(images_np)\n",
    "labels_np = np.concatenate(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfaf729-3cfe-40bd-9fa6-3361e749d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is as in the MNIST examples.\n",
    "# so see those notebooks for some notes on the binning.\n",
    "bins = np.arange(-0.5, 256.5, 1) / 255\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(images_np.reshape(-1), bins=bins)\n",
    "plt.title(\"Pixel distribution (linear)\")\n",
    "plt.xlabel(\"Pixel value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# now the labels\n",
    "bins = np.arange(-0.5, 10.5, 1)\n",
    "plt.hist(labels_np, bins=bins)\n",
    "plt.hlines(5000, -1, 10, colors=\"red\", linestyles=\"dashed\", label=\"Ideal balance\")\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.xlim(-1, 10)\n",
    "plt.title(\"Label distribution\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefe8f3-30bc-4732-a8b2-f63992494149",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Here we build a simple MLP with three hidden layers with 1024 units each and GELU activation. This is by no means an ideal architecture, so you can tune it if you wish. It just serves as a starting point.\n",
    "\n",
    "The `model` object is where you would include Batch Normalization and/or Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ea3d9-1837-4cbc-8604-753636015046",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(32*32*3, 1024),\n",
    "                      nn.GELU(),\n",
    "                      nn.Linear(1024, 1024),\n",
    "                      nn.GELU(),\n",
    "                      nn.Linear(1024, 1024),\n",
    "                      nn.GELU(),\n",
    "                      nn.Linear(1024, 10)).to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def glorot_init(layer: nn.Module):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        nn.init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.apply(glorot_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9525039-a21d-4436-84a3-0198e1c64a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this learning rate is fairly high and somewhat at the \"edge of chaos\"\n",
    "# -- we are risking our model diverging and getting \"nan\" loss.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66f666-6ea2-4e66-bef8-175cadd13b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, \n",
    "                loss_fn: nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                training_loader: DataLoader, \n",
    "                validation_loader: DataLoader,\n",
    "                n_epochs: int,\n",
    "                verbose: bool = True):\n",
    "    n_training_examples = len(training_loader.dataset)\n",
    "    batches_per_epoch = n_training_examples // training_loader.batch_size\n",
    "    print(\"Running {} epochs at {} steps per epoch.\".format(n_epochs, batches_per_epoch))\n",
    "    \n",
    "    # note, for training we only track the average over the epoch.\n",
    "    # this is somewhat imprecise, as the model changes over the epoch.\n",
    "    # so the metrics at the end of the epoch will usually be better than at the start,\n",
    "    # but we average over everything.\n",
    "    # we could record train metrics more often to get a better picture of training progress.\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    writer = SummaryWriter(\"runs_cifar/lr0p05\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if verbose:\n",
    "            print(\"Starting epoch {}...\".format(epoch + 1), end=\" \")\n",
    "\n",
    "        start_time = perf_counter()\n",
    "        epoch_train_losses = []\n",
    "        epoch_train_accuracies = []\n",
    "        \n",
    "        model.train()\n",
    "        for batch_ind, (input_batch, label_batch) in enumerate(training_loader):\n",
    "            total_step = batch_ind + batches_per_epoch * epoch\n",
    "            batch_loss, batch_accuracy = train_step(input_batch, label_batch, model, loss_fn, optimizer, \n",
    "                                                    writer, total_step)\n",
    "            epoch_train_losses.append(batch_loss.item())\n",
    "            epoch_train_accuracies.append(batch_accuracy.item())\n",
    "        \n",
    "        end_time = perf_counter()\n",
    "        time_taken = end_time - start_time\n",
    "            \n",
    "        # evaluate after each epoch\n",
    "        val_loss, val_accuracy = evaluate(model, validation_loader, loss_fn)\n",
    "            \n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy.item())\n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        train_accuracies.append(np.mean(epoch_train_accuracies))\n",
    "        \n",
    "        writer.add_scalars(\"loss\", {\"train\": np.mean(epoch_train_losses), \"valid\": val_loss.item()}, epoch)\n",
    "        writer.add_scalars(\"accuracy\", {\"train\": np.mean(epoch_train_accuracies), \"valid\": val_accuracy.item()}, epoch)\n",
    "        writer.flush()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Time taken: {} seconds\".format(time_taken))\n",
    "            print(\"\\tTrain/val loss: {} / {}\".format(train_losses[-1], val_losses[-1]))\n",
    "            print(\"\\tTrain/val accuracy: {} / {}\".format(train_accuracies[-1], val_accuracies[-1]))\n",
    "        \n",
    "    return {\"train_loss\": np.array(train_losses), \"train_accuracy\": np.array(train_accuracies),\n",
    "            \"val_loss\": np.array(val_losses), \"val_accuracy\": np.array(val_accuracies)}\n",
    "\n",
    "\n",
    "def train_step(input_batch, label_batch, model, loss_fn, optimizer, writer, total_step):\n",
    "    input_batch = input_batch.to(device)\n",
    "    label_batch = label_batch.to(device)\n",
    "    output_batch = model(input_batch)\n",
    "    batch_loss = loss_fn(output_batch, label_batch)\n",
    "    \n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if not total_step % 100:\n",
    "            for name, parameter in model.named_parameters():\n",
    "                writer.add_scalar(\"gradient_\" + name, torch.sqrt((parameter.grad**2).sum()), total_step)\n",
    "                writer.add_histogram(name, parameter, total_step)\n",
    "            writer.add_images(\"images\", input_batch, total_step)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        batch_accuracy = accuracy(label_batch, output_batch)\n",
    "    return batch_loss, batch_accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_batch, label_batch in dataloader:\n",
    "            input_batch = input_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            predictions = model(input_batch)\n",
    "            val_loss += loss_fn(predictions, label_batch)\n",
    "            correct += (predictions.argmax(axis=1) == label_batch).type(torch.float).sum()\n",
    "            \n",
    "        val_loss /= num_batches\n",
    "        val_accuracy = correct / size\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def accuracy(labels: torch.tensor,\n",
    "             outputs: torch.tensor) -> torch.tensor:\n",
    "    predictions = torch.argmax(outputs, axis=-1)\n",
    "    matches = labels == predictions\n",
    "    return matches.float().mean()\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Usage: When you start training, create an instance of this class with the model.\n",
    "           patience describes how many epochs without improvement to tolerate before stopping.\n",
    "           min_delta can be set to determine what kind of improvement actually counts.\n",
    "           An improvement below this value will not be counted.\n",
    "\n",
    "           Every epoch, after computing the val_loss, call should_stop = early_stopper.update(val_loss).\n",
    "           If should_stop is True, you should abort training, i.e. \n",
    "               if should_stop: break\n",
    "           to escape the training loop. \n",
    "           The update function automatically stores the best model seen so far, and reloads it before stopping.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, patience, direction=\"min\", min_delta=0.0001, verbose=False):\n",
    "        if direction not in [\"min\", \"max\"]:\n",
    "            raise ValueError(\"direction should be 'min' or 'max', you passed {}\".format(direction))\n",
    "        self.best_state_dict = {key: None for key in model.state_dict()}\n",
    "        self.best_value = np.inf if direction == \"min\" else -np.inf\n",
    "        self.direction = direction\n",
    "        self.min_delta = min_delta\n",
    "        self.model = model\n",
    "\n",
    "        self.patience = patience\n",
    "        self.disappointment = 0\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def update(self, value):\n",
    "        if ((self.direction == \"min\" and value < self.best_value - self.min_delta) \n",
    "            or (self.direction == \"max\" and value > self.best_value + self.min_delta)):\n",
    "            self.best_value = value\n",
    "            for key in model.state_dict():\n",
    "                self.best_state_dict[key] = model.state_dict()[key].clone()\n",
    "            self.disappointment = 0\n",
    "            if self.verbose:\n",
    "                print(\"New best value found; no longer disappointed\")\n",
    "            return 0\n",
    "        else:\n",
    "            self.disappointment += 1\n",
    "            if self.verbose:\n",
    "                print(\"EarlyStopping disappointment increased to {}\".format(self.disappointment))\n",
    "\n",
    "            if self.disappointment > self.patience:\n",
    "                if self.verbose:\n",
    "                    print(\"EarlyStopping has become too disappointed; now would be a good time to cancel training\")\n",
    "                    print(\"Restoring best model from state_dict\")\n",
    "                self.model.load_state_dict(self.best_state_dict)\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588602c-523f-47a7-a1ef-74381a0b95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_model(model, loss_fn, optimizer, train_dataloader, test_dataloader,\n",
    "                      n_epochs=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228fa8f-9cb1-493a-b282-740ebb6829ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics[\"train_loss\"], label=\"train\")\n",
    "plt.plot(metrics[\"val_loss\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(metrics[\"train_accuracy\"], label=\"train\")\n",
    "plt.plot(metrics[\"val_accuracy\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129370a5-5cf1-421f-a4b1-e2bcdf90a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs_cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7343d55-3870-4f35-be43-5c7e738f177e",
   "metadata": {},
   "source": [
    "We can once again attempt to visualize the features learned by the first layer via plotting the weights in the shape of the input images. However, this becomes difficult to do \"correctly\" because we now have color images. With MNIST, we only had a single color channel, and so could plot the weights in different colors for positive/negative values. This no longer works with multiple input channels -- we have to plot the weights in RGB space. But this makes it impossible to really show positive/negative weights. The best we can do is somehow normalize the weights into the [0, 1] range. Then, bright values would indicate positive weights and ark values negative weights (for each color, respectively).\n",
    "\n",
    "As such, don't worry too much about interpreting the plots below. Still, we will see that a properly trained and regularized model will have much more \"distinct\" features rather than the nosiy mess we have right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b22b61-9337-4a99-81bc-cdd5ae44e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(colormap=\"local\", normalization=\"symmetric\"):\n",
    "    if colormap not in [\"local\", \"global\"]:\n",
    "        raise ValueError(\"colormap argument should be 'local' or 'global'\")\n",
    "    if normalization not in [\"symmetric\", \"full\"]:\n",
    "        raise ValueError (\"normalization should be 'symmetric' (map 0 weights to 0.5) \"\n",
    "                          \"or 'full' (map minimum to 0 and maximum to 1)\")\n",
    "    \n",
    "    features = model[1].weight.detach().cpu().numpy()\n",
    "    if colormap == \"global\":\n",
    "        if normalization == \"full\":\n",
    "            features -= features.min()\n",
    "            features /= features.max()\n",
    "        else:\n",
    "            absmax = abs(features).max()\n",
    "            features /= 2*absmax\n",
    "            features += 0.5\n",
    "\n",
    "    plt.figure(figsize=(12, 24))\n",
    "    for ind, pattern in enumerate(features):\n",
    "        if colormap == \"local\":\n",
    "            if normalization == \"full\":\n",
    "                pattern -= pattern.min()\n",
    "                pattern /= pattern.max()\n",
    "            else:\n",
    "                absmax = abs(pattern).max()\n",
    "                pattern /= 2*absmax\n",
    "                pattern += 0.5\n",
    "        \n",
    "        plt.subplot(64, 32, ind+1)\n",
    "        pattern = pattern.reshape(3, 32, 32).transpose((1, 2, 0))\n",
    "        plt.imshow(pattern)\n",
    "        plt.axis(\"off\")\n",
    "        #plt.colorbar()\n",
    "    plt.suptitle(\"First layer features with {} colormaps and {} normalization\".format(colormap, normalization))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67af89c-4b42-4f10-b475-83ebbfb68e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_features(\"local\", \"full\")\n",
    "#visualize_features(\"global\", \"full\")\n",
    "\n",
    "#visualize_features(\"local\", \"symmetric\")\n",
    "visualize_features(\"global\", \"symmetric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d98f1-e450-428b-b0b1-2f89d23c6af1",
   "metadata": {},
   "source": [
    "Finally, it's always a good idea at some classification results on the held-out data. We can see that the model does a good job an some examples, but fails badly on many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f50bb3-8919-4694-99ec-e450bf160093",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        probabilities = torch.nn.functional.softmax(model(X.to(device)), dim=1)\n",
    "        predictions = probabilities.argmax(axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for ind, img in enumerate(X[:36]):\n",
    "        pred_here = predictions[ind]\n",
    "        prob_here = probabilities[ind, pred_here].item()\n",
    "        true_here = y[ind]\n",
    "        \n",
    "        plt.subplot(6, 6, ind+1)\n",
    "        plt.imshow(img.permute((1, 2, 0)))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.title(\"true: {} pred: {}\\nprob: {:.3f}\".format(classes[true_here], classes[pred_here], prob_here),\n",
    "                  fontsize=8)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e46171-1a99-4700-a943-c33cdf4fa1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
